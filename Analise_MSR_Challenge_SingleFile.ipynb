{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter\n",
        "import copy"
      ],
      "metadata": {
        "id": "XJelQc_9DDiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xkCubDqOwsLO"
      },
      "outputs": [],
      "source": [
        "# Datasets and list of synonyms path\n",
        "commit_sharing = \"./20231012_230826_commit_sharings.json\"\n",
        "pull_request_sharing = \"./20231012_233628_pr_sharings.json\"\n",
        "issue_sharing = \"./20231012_235128_issue_sharings.json\"\n",
        "file_sharings = \"./20231012_234250_file_sharings.json\"\n",
        "discussion_sharings = \"./20231012_235320_discussion_sharings.json\"\n",
        "\n",
        "path_list_synonym = \"./synonyms_for_normalization.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jsons_list = [commit_sharing,pull_request_sharing,issue_sharing,file_sharings,discussion_sharings]\n",
        "jsons_file = ['commit_sharing','pull_request_sharing','issue_sharing','file_sharings','discussion_sharings']"
      ],
      "metadata": {
        "id": "860F2dPlQgLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abra o arquivo json\n",
        "\n",
        "# 0 = commit_sharing, 1 = pull_request_sharing, 2 = issue_sharing, 3 = file_sharings, 4 = discussion_sharings\n",
        "fileNumber = 4\n",
        "\n",
        "with open(jsons_list[fileNumber], 'r') as f:\n",
        "    dados1 = json.load(f)\n",
        "\n",
        "json_processado_output = jsons_file[fileNumber]+'.json'"
      ],
      "metadata": {
        "id": "G0H1Vn_9DSQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalisation"
      ],
      "metadata": {
        "id": "xUf5s_I2gNzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing synonym_list file\n",
        "with open(path_list_synonym, 'r') as arquivo:\n",
        "    # dict to store the synonyms\n",
        "    synonyms = {}\n",
        "    for linha in arquivo:\n",
        "        chave, valor = linha.strip().split('=')\n",
        "\n",
        "        synonyms[chave.strip()] = valor.strip().split(',')\n"
      ],
      "metadata": {
        "id": "ct6HtMabeNyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for elementos in dados1[\"Sources\"]:\n",
        "  if elementos[\"RepoLanguage\"] == None :\n",
        "      elementos[\"RepoLanguage\"] = \"none\"\n",
        "  else:\n",
        "    for linguagem, alias in synonyms.items():\n",
        "      if elementos[\"RepoLanguage\"] in alias:\n",
        "        elementos[\"RepoLanguage\"] = linguagem\n",
        "\n",
        "\n",
        "\n",
        "for elementos in dados1[\"Sources\"]:\n",
        "  for elemento in elementos[\"ChatgptSharing\"]:\n",
        "    if \"Conversations\" in elemento and elemento[\"Conversations\"]:\n",
        "      for conversation in elemento[\"Conversations\"]:\n",
        "        if \"ListOfCode\" in conversation and conversation[\"ListOfCode\"]:\n",
        "          for snipetType in conversation[\"ListOfCode\"]:\n",
        "            if snipetType[\"Type\"] == None :\n",
        "              snipetType[\"Type\"] = \"none\"\n",
        "            else:\n",
        "              for linguagem, alias in synonyms.items():\n",
        "                if  snipetType[\"Type\"] in alias:\n",
        "                  snipetType[\"Type\"] = linguagem\n"
      ],
      "metadata": {
        "id": "oQ2Jn8hvG4ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# write processed json\n",
        "with open(jsons_file[j]+'.json', 'w') as arquivo:\n",
        "  json.dump(dados1, arquivo)"
      ],
      "metadata": {
        "id": "DyzWMR08Ayrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction"
      ],
      "metadata": {
        "id": "HpGcZcGYf9wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repoLang = []\n",
        "for elementos in dados1[\"Sources\"]:\n",
        "  repoLang.append(elementos[\"RepoLanguage\"])\n"
      ],
      "metadata": {
        "id": "WLwJtazqGgIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contagem = Counter(repoLang)\n",
        "contagem\n",
        "\n",
        "contagemDict = dict(contagem)"
      ],
      "metadata": {
        "id": "vkrJphY-XhDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.DataFrame(list(contagemDict.items()), columns=['Language', 'Count'])"
      ],
      "metadata": {
        "id": "JeKQaHupXo9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repoByLanguage = {}\n",
        "\n",
        "for key in contagem.keys():\n",
        "  repoByLanguage.setdefault(key, [])\n",
        "  for elementos in dados1[\"Sources\"]:\n",
        "    if elementos[\"RepoLanguage\"] == key:\n",
        "      repoByLanguage[key].append(elementos[\"RepoName\"])\n"
      ],
      "metadata": {
        "id": "jAUk6iuvcMPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(list(repoByLanguage.items()), columns=['Language', 'Repos'])"
      ],
      "metadata": {
        "id": "-3FmmUfKuFht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repoByLanguageCount = copy.deepcopy(repoByLanguage)\n",
        "\n",
        "for chave, lista in repoByLanguage.items():\n",
        "    repoByLanguage[chave] = list(set(lista))\n",
        "    repoByLanguageCount[chave] = len(list(set(lista)))"
      ],
      "metadata": {
        "id": "tIwI7ZYt8SWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(list(repoByLanguage.items()), columns=['Language', 'UniqueRepos'])\n",
        "df3 = pd.DataFrame(list(repoByLanguageCount.items()), columns=['Language', 'UniqueReposCount'])"
      ],
      "metadata": {
        "id": "1MqOCA13jk16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountChat"
      ],
      "metadata": {
        "id": "hTB8tUaa8ZgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatByLanguage = {}\n",
        "for elementos in dados1[\"Sources\"]:\n",
        "  chatByLanguage.setdefault(elementos[\"RepoLanguage\"], [])\n",
        "  for elemento in elementos[\"ChatgptSharing\"]:\n",
        "    chatByLanguage[elementos[\"RepoLanguage\"]].append(elemento[\"URL\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "_Gj2Ig-q8bon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatByLanguage[\"None\"] = chatByLanguage[None]\n",
        "# del chatByLanguage[None]"
      ],
      "metadata": {
        "id": "4fgj7EmtM8Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame(list(chatByLanguage.items()), columns=['Language', 'Chat'])\n",
        "# df.to_csv('chatByLanguage.csv', index=False)"
      ],
      "metadata": {
        "id": "bfyDGygyKSc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatByLanguageCount = copy.deepcopy(chatByLanguage)\n",
        "for chave, lista in chatByLanguage.items():\n",
        "    chatByLanguage[chave] = list(set(lista))\n",
        "    chatByLanguageCount[chave] = len(list(set(lista)))"
      ],
      "metadata": {
        "id": "wf782MlrOM11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatByLanguage\n",
        "df5 = pd.DataFrame(list(chatByLanguage.items()), columns=['Language', 'UniqueChat'])\n",
        "df6 = pd.DataFrame(list(chatByLanguageCount.items()), columns=['Language', 'UniqueChatCount'])\n",
        "# df.to_csv('uniqueChatByLanguage.csv', index=False)"
      ],
      "metadata": {
        "id": "7BVGqJuNO5Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Snipets"
      ],
      "metadata": {
        "id": "rA4B5g7kRJQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snipetsByLanguage = {}\n",
        "for elementos in dados1[\"Sources\"]:\n",
        "  snipetsByLanguage.setdefault(elementos[\"RepoLanguage\"], [])\n",
        "  for elemento in elementos[\"ChatgptSharing\"]:\n",
        "    if \"Conversations\" in elemento and elemento[\"Conversations\"]:\n",
        "      for conversation in elemento[\"Conversations\"]:\n",
        "        if \"ListOfCode\" in conversation and conversation[\"ListOfCode\"]:\n",
        "          for snipetType in conversation[\"ListOfCode\"]:\n",
        "            snipetsByLanguage[elementos[\"RepoLanguage\"]].append(snipetType[\"Type\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "YYF_L6rKRMHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snipetsByLanguage\n",
        "snipetsByLanguagePercentage = copy.deepcopy(snipetsByLanguage)\n",
        "snipetsByLanguageTotal = copy.deepcopy(snipetsByLanguage)"
      ],
      "metadata": {
        "id": "IdlUVMODhMzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for chave, lista in snipetsByLanguage.items():\n",
        "    # Calcular a contagem total de elementos na lista atual\n",
        "    total_elementos_lista = len(lista)\n",
        "\n",
        "    # Calcular a contagem de elementos na lista atual\n",
        "    contagem_elementos = Counter(lista)\n",
        "\n",
        "    # Calcular a porcentagem de ocorrência de cada elemento na lista atual\n",
        "    snipetsByLanguagePercentage[chave] = {elemento: f'{(ocorrencias / total_elementos_lista) * 100:.3f}' for elemento, ocorrencias in contagem_elementos.items()}\n",
        "    snipetsByLanguage[chave] = dict(Counter(snipetsByLanguage[chave]))\n",
        "    snipetsByLanguageTotal[chave] = (sum(Counter(snipetsByLanguage[chave]).values()))"
      ],
      "metadata": {
        "id": "mV5BHs_M1vj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = pd.DataFrame(list(snipetsByLanguage.items()), columns=['Language', 'SnippetLang'])\n",
        "\n",
        "df8 = pd.DataFrame(list(snipetsByLanguageTotal.items()), columns=['Language', 'SnippetLangCount'])\n",
        "\n",
        "df9 = pd.DataFrame(list(snipetsByLanguagePercentage.items()), columns=['Language', 'SnippetLangPercentage'])\n",
        "\n",
        "df_concatenado = pd.merge(df0, df1, on='Language').merge(df2, on='Language').merge(df3, on='Language').merge(df4, on='Language')\n",
        "df_concatenado = df_concatenado.merge(df5, on='Language').merge(df6, on='Language').merge(df7, on='Language').merge(df8, on='Language').merge(df9, on='Language')\n",
        "df_concatenado.to_csv(jsons_file[j]+'_results_table.csv', index=False)"
      ],
      "metadata": {
        "id": "qn1uD23vcto2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Snipets by language"
      ],
      "metadata": {
        "id": "k59i_LgyEzBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linhas = []\n",
        "for coluna, valores in snipetsByLanguage.items():\n",
        "    linha = {'linguagem': coluna}  # Adicione a coluna principal\n",
        "    linha.update(valores)  # Adicione os valores da linguagem\n",
        "    linhas.append(linha)\n",
        "\n",
        "# Criação do DataFrame\n",
        "snipetsByLanguageDF = pd.DataFrame(linhas)\n",
        "snipetsByLanguageDF = snipetsByLanguageDF.T\n",
        "\n",
        "\n",
        "# Exibindo o DataFrame\n",
        "snipetsByLanguageDF = snipetsByLanguageDF.fillna(0)\n",
        "snipetsByLanguageDF.to_csv(jsons_file[j]+'_snipetsByLanguageDF.csv')"
      ],
      "metadata": {
        "id": "HQDjZn-VsvqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Snipets By Language in Percentage"
      ],
      "metadata": {
        "id": "n5FOo_xrF6hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linhas = []\n",
        "for coluna, valores in snipetsByLanguagePercentage.items():\n",
        "    linha = {'linguagem': coluna}  # Adicione a coluna principal\n",
        "    linha.update(valores)  # Adicione os valores da linguagem\n",
        "    linhas.append(linha)\n",
        "\n",
        "# Criação do DataFrame\n",
        "snipetsByLanguagePercentageDF = pd.DataFrame(linhas)\n",
        "snipetsByLanguagePercentageDF = snipetsByLanguagePercentageDF.T\n",
        "\n",
        "# Exibindo o DataFrame\n",
        "snipetsByLanguagePercentageDF = snipetsByLanguagePercentageDF.fillna(0)\n",
        "snipetsByLanguagePercentageDF.to_csv(jsons_file[j]+'_snipetsByLanguagePercentageDF.csv')"
      ],
      "metadata": {
        "id": "vH1qo3Mq1I-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}