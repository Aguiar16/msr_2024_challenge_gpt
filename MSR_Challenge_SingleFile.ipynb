{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJelQc_9DDiR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xkCubDqOwsLO"
      },
      "outputs": [],
      "source": [
        "# Datasets and list of synonyms path\n",
        "commit_sharing = \"./20231012_230826_commit_sharings.json\"\n",
        "pull_request_sharing = \"./20231012_233628_pr_sharings.json\"\n",
        "issue_sharing = \"./20231012_235128_issue_sharings.json\"\n",
        "file_sharings = \"./20231012_234250_file_sharings.json\"\n",
        "discussion_sharings = \"./20231012_235320_discussion_sharings.json\"\n",
        "\n",
        "path_list_synonym = \"./synonyms_for_normalization.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "860F2dPlQgLa"
      },
      "outputs": [],
      "source": [
        "jsons_list = [commit_sharing,pull_request_sharing,issue_sharing,file_sharings,discussion_sharings]\n",
        "jsons_file = ['commit_sharing','pull_request_sharing','issue_sharing','file_sharings','discussion_sharings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0H1Vn_9DSQq"
      },
      "outputs": [],
      "source": [
        "# 0 = commit_sharing, 1 = pull_request_sharing, 2 = issue_sharing, 3 = file_sharings, 4 = discussion_sharings\n",
        "fileNumber = 4\n",
        "\n",
        "with open(jsons_list[fileNumber], 'r') as f:\n",
        "    data1 = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUf5s_I2gNzI"
      },
      "source": [
        "# Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct6HtMabeNyb"
      },
      "outputs": [],
      "source": [
        "# Pre-processing synonym_list file\n",
        "with open(path_list_synonym, 'r') as arquivo:\n",
        "    # dict to store the synonyms\n",
        "    synonyms = {}\n",
        "    for linha in arquivo:\n",
        "        chave, valor = linha.strip().split('=')\n",
        "\n",
        "        synonyms[chave.strip()] = valor.strip().split(',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ2Jn8hvG4ub"
      },
      "outputs": [],
      "source": [
        "\n",
        "for elementos in data1[\"Sources\"]:\n",
        "  if elementos[\"RepoLanguage\"] == None :\n",
        "      elementos[\"RepoLanguage\"] = \"none\"\n",
        "  else:\n",
        "    for linguagem, alias in synonyms.items():\n",
        "      if elementos[\"RepoLanguage\"] in alias:\n",
        "        elementos[\"RepoLanguage\"] = linguagem\n",
        "\n",
        "\n",
        "\n",
        "for elementos in data1[\"Sources\"]:\n",
        "  for elemento in elementos[\"ChatgptSharing\"]:\n",
        "    if \"Conversations\" in elemento and elemento[\"Conversations\"]:\n",
        "      for conversation in elemento[\"Conversations\"]:\n",
        "        if \"ListOfCode\" in conversation and conversation[\"ListOfCode\"]:\n",
        "          for snipetType in conversation[\"ListOfCode\"]:\n",
        "            if snipetType[\"Type\"] == None :\n",
        "              snipetType[\"Type\"] = \"none\"\n",
        "            else:\n",
        "              for linguagem, alias in synonyms.items():\n",
        "                if  snipetType[\"Type\"] in alias:\n",
        "                  snipetType[\"Type\"] = linguagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyzWMR08Ayrq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# write processed json\n",
        "with open(\"./normalised/\"+jsons_file[j]+'.json', 'w') as arquivo:\n",
        "  json.dump(data1, arquivo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpGcZcGYf9wg"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLwJtazqGgIJ"
      },
      "outputs": [],
      "source": [
        "repoLang = []\n",
        "for elementos in data1[\"Sources\"]:\n",
        "  repoLang.append(elementos[\"RepoLanguage\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkrJphY-XhDI"
      },
      "outputs": [],
      "source": [
        "counting = Counter(repoLang)\n",
        "\n",
        "countingDict = dict(counting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeKQaHupXo9R"
      },
      "outputs": [],
      "source": [
        "df0 = pd.DataFrame(list(countingDict.items()), columns=['Language', 'Count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAUk6iuvcMPq"
      },
      "outputs": [],
      "source": [
        "repoByLanguage = {}\n",
        "\n",
        "for key in counting.keys():\n",
        "  repoByLanguage.setdefault(key, [])\n",
        "  for elements in data1[\"Sources\"]:\n",
        "    if elements[\"RepoLanguage\"] == key:\n",
        "      repoByLanguage[key].append(elements[\"RepoName\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3FmmUfKuFht"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(list(repoByLanguage.items()), columns=['Language', 'Repos'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIwI7ZYt8SWp"
      },
      "outputs": [],
      "source": [
        "repoByLanguageCount = copy.deepcopy(repoByLanguage)\n",
        "\n",
        "for key, alias in repoByLanguage.items():\n",
        "    repoByLanguage[key] = list(set(alias))\n",
        "    repoByLanguageCount[key] = len(list(set(alias)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MqOCA13jk16"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(list(repoByLanguage.items()), columns=['Language', 'UniqueRepos'])\n",
        "df3 = pd.DataFrame(list(repoByLanguageCount.items()), columns=['Language', 'UniqueReposCount'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTB8tUaa8ZgH"
      },
      "source": [
        "## CountChat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gj2Ig-q8bon"
      },
      "outputs": [],
      "source": [
        "chatByLanguage = {}\n",
        "for elements in data1[\"Sources\"]:\n",
        "  chatByLanguage.setdefault(elements[\"RepoLanguage\"], [])\n",
        "  for element in elements[\"ChatgptSharing\"]:\n",
        "    chatByLanguage[elements[\"RepoLanguage\"]].append(element[\"URL\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfyDGygyKSc1"
      },
      "outputs": [],
      "source": [
        "df4 = pd.DataFrame(list(chatByLanguage.items()), columns=['Language', 'Chat'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf782MlrOM11"
      },
      "outputs": [],
      "source": [
        "chatByLanguageCount = copy.deepcopy(chatByLanguage)\n",
        "for key, alias in chatByLanguage.items():\n",
        "    chatByLanguage[key] = list(set(alias))\n",
        "    chatByLanguageCount[key] = len(list(set(alias)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BVGqJuNO5Ar"
      },
      "outputs": [],
      "source": [
        "chatByLanguage\n",
        "df5 = pd.DataFrame(list(chatByLanguage.items()), columns=['Language', 'UniqueChat'])\n",
        "df6 = pd.DataFrame(list(chatByLanguageCount.items()), columns=['Language', 'UniqueChatCount'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA4B5g7kRJQB"
      },
      "source": [
        "## Code Snipets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYF_L6rKRMHM"
      },
      "outputs": [],
      "source": [
        "snipetsByLanguage = {}\n",
        "for elements in data1[\"Sources\"]:\n",
        "  snipetsByLanguage.setdefault(elements[\"RepoLanguage\"], [])\n",
        "  for element in elements[\"ChatgptSharing\"]:\n",
        "    if \"Conversations\" in element and element[\"Conversations\"]:\n",
        "      for conversation in element[\"Conversations\"]:\n",
        "        if \"ListOfCode\" in conversation and conversation[\"ListOfCode\"]:\n",
        "          for snipetType in conversation[\"ListOfCode\"]:\n",
        "            snipetsByLanguage[elements[\"RepoLanguage\"]].append(snipetType[\"Type\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdlUVMODhMzz"
      },
      "outputs": [],
      "source": [
        "snipetsByLanguage\n",
        "snipetsByLanguagePercentage = copy.deepcopy(snipetsByLanguage)\n",
        "snipetsByLanguageTotal = copy.deepcopy(snipetsByLanguage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV5BHs_M1vj2"
      },
      "outputs": [],
      "source": [
        "\n",
        "for key, alias in snipetsByLanguage.items():\n",
        "    total_elements_on_lista = len(alias)\n",
        "\n",
        "    count_elements = Counter(alias)\n",
        "\n",
        "    snipetsByLanguagePercentage[key] = {element: f'{(ocurrency / total_elements_on_lista) * 100:.3f}' for element, ocurrency in count_elements.items()}\n",
        "    snipetsByLanguage[key] = dict(Counter(snipetsByLanguage[key]))\n",
        "    snipetsByLanguageTotal[key] = (sum(Counter(snipetsByLanguage[key]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn1uD23vcto2"
      },
      "outputs": [],
      "source": [
        "df7 = pd.DataFrame(list(snipetsByLanguage.items()), columns=['Language', 'SnippetLang'])\n",
        "\n",
        "df8 = pd.DataFrame(list(snipetsByLanguageTotal.items()), columns=['Language', 'SnippetLangCount'])\n",
        "\n",
        "df9 = pd.DataFrame(list(snipetsByLanguagePercentage.items()), columns=['Language', 'SnippetLangPercentage'])\n",
        "\n",
        "df_concat = pd.merge(df0, df1, on='Language').merge(df2, on='Language').merge(df3, on='Language').merge(df4, on='Language')\n",
        "df_concat = df_concat.merge(df5, on='Language').merge(df6, on='Language').merge(df7, on='Language').merge(df8, on='Language').merge(df9, on='Language')\n",
        "df_concat.to_csv(jsons_file[j]+'_results_table.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k59i_LgyEzBg"
      },
      "source": [
        "## Verify Snipets by language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQDjZn-VsvqY"
      },
      "outputs": [],
      "source": [
        "\n",
        "rows = []\n",
        "for columns, values in snipetsByLanguage.items():\n",
        "    row = {'language': columns}\n",
        "    row.update(values)\n",
        "    rows.append(row)\n",
        "\n",
        "snipetsByLanguageDF = pd.DataFrame(rows)\n",
        "snipetsByLanguageDF = snipetsByLanguageDF.T\n",
        "\n",
        "\n",
        "snipetsByLanguageDF = snipetsByLanguageDF.fillna(0)\n",
        "snipetsByLanguageDF.to_csv(jsons_file[j]+'_snipetsByLanguageDF.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5FOo_xrF6hT"
      },
      "source": [
        "## Snipets By Language in Percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH1qo3Mq1I-f"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "for columns, values in snipetsByLanguagePercentage.items():\n",
        "    row = {'language': columns}\n",
        "    row.update(values)\n",
        "    rows.append(row)\n",
        "\n",
        "snipetsByLanguagePercentageDF = pd.DataFrame(rows)\n",
        "snipetsByLanguagePercentageDF = snipetsByLanguagePercentageDF.T\n",
        "\n",
        "snipetsByLanguagePercentageDF = snipetsByLanguagePercentageDF.fillna(0)\n",
        "snipetsByLanguagePercentageDF.to_csv(jsons_file[j]+'_snipetsByLanguagePercentageDF.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
